# V1.1 Enhancement Specifications

## Technical Review Integration

**Status:** Proposed Enhancements  
**Source:** Data Science & Systems Architecture Review (December 2024)  
**Priority:** Phase 2 Optimizations

---

## Overview

This document captures enhancements recommended during technical review that are deferred to v1.1. The Bayesian Calibrator (Recommendation A) has been integrated into the core schemas. The following remain as Phase 2 work.

**Integrated in v1.0:**
- ✅ Bayesian Competence Model (`BayesianPrior`, updated `CompetenceEntry`)
- ✅ Humble Prompt Injection (`inject_into_prompt()` method)

**Deferred to v1.1:**
- ⏳ Strategy Compressor (Recommendation B)
- ⏳ Metamemory FoK Regressor (Recommendation C)

---

## Enhancement B: Strategy Compressor

### Problem Statement

The Procedural layer (ReasoningBank-style) uses append-only consolidation. Over time this creates:

1. **Redundant strategies**: "Fixing SQL timeout" and "Fixing API timeout" stored separately despite identical core logic
2. **Retrieval noise**: Similar strategies compete in vector search
3. **Transfer failure**: Agent can't generalize "timeout handling" across contexts

### Proposed Solution

Implement periodic consolidation via hierarchical clustering + LLM abstraction.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        STRATEGY COMPRESSOR                               │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│   RAW MEMORY STREAM                                                     │
│   ─────────────────                                                     │
│   │ "Fixing SQL timeout by increasing pool..."                          │
│   │ "Fixing API timeout by adding retry..."                             │
│   │ "Fixing HTTP 504 by checking upstream..."                           │
│   │ "Fixing connection timeout in database..."                          │
│   ▼                                                                     │
│                                                                         │
│   ┌─────────────────────────────────────────────────────────────────┐  │
│   │                    CLUSTERING ENGINE                             │  │
│   │                                                                  │  │
│   │  Algorithm: DBSCAN or HDBSCAN                                   │  │
│   │  Features: Strategy embeddings                                   │  │
│   │  Parameters: eps=0.3, min_samples=3                             │  │
│   │                                                                  │  │
│   └──────────────────────────┬──────────────────────────────────────┘  │
│                              │                                          │
│                              ▼                                          │
│   ┌──────────────────────────────────────────────────────────────────┐ │
│   │  CLUSTER #104: Timeout Handling                                  │ │
│   │  ├── SQL timeout strategy                                        │ │
│   │  ├── API timeout strategy                                        │ │
│   │  ├── HTTP 504 strategy                                           │ │
│   │  └── Connection timeout strategy                                 │ │
│   └──────────────────────────┬───────────────────────────────────────┘ │
│                              │                                          │
│                              ▼                                          │
│   ┌──────────────────────────────────────────────────────────────────┐ │
│   │                    LLM ABSTRACTION LAYER                         │ │
│   │                                                                  │ │
│   │  Prompt: "Read these 4 related strategies. Extract the shared   │ │
│   │           abstract principle that applies across all contexts.   │ │
│   │           Produce a single generalized strategy."                │ │
│   │                                                                  │ │
│   └──────────────────────────┬───────────────────────────────────────┘ │
│                              │                                          │
│                              ▼                                          │
│   ┌──────────────────────────────────────────────────────────────────┐ │
│   │  NEW ABSTRACT STRATEGY                                           │ │
│   │                                                                  │ │
│   │  Title: "Universal Timeout Handling Protocol"                    │ │
│   │  Description: "When any operation exceeds expected duration..."  │ │
│   │  Content: "1. Identify timeout type (connection/read/write)     │ │
│   │            2. Check resource availability                        │ │
│   │            3. Implement exponential backoff retry                │ │
│   │            4. Add circuit breaker if persistent                  │ │
│   │            5. Log with context for diagnosis"                    │ │
│   │                                                                  │ │
│   │  Subsumes: [strategy_104a, strategy_104b, strategy_104c, ...]   │ │
│   │  Abstraction_level: 2 (domain-general)                          │ │
│   │                                                                  │ │
│   └──────────────────────────────────────────────────────────────────┘ │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Schema Extension

```python
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Optional, Dict
from enum import Enum


class AbstractionLevel(Enum):
    """How general/transferable a strategy is."""
    INSTANCE = 0        # Specific to one task instance
    TASK_SPECIFIC = 1   # Applies to similar tasks
    DOMAIN_GENERAL = 2  # Applies across domain
    UNIVERSAL = 3       # Applies across domains


@dataclass
class StrategyCluster:
    """
    A cluster of related strategies identified during consolidation.
    """
    
    id: str
    label: str                              # Human-readable cluster name
    
    # Member strategies
    member_ids: List[str]                   # MemoryItem IDs in this cluster
    centroid_embedding: List[float]         # Cluster centroid for retrieval
    
    # Clustering metadata
    cohesion_score: float                   # How tight the cluster is (0-1)
    created_at: datetime = field(default_factory=datetime.now)
    
    # Abstraction result
    abstract_strategy_id: Optional[str] = None  # Generated abstract strategy
    abstraction_level: AbstractionLevel = AbstractionLevel.TASK_SPECIFIC


@dataclass
class AbstractStrategy:
    """
    A strategy generated by abstracting over a cluster of specific strategies.
    Extends MemoryItem with abstraction metadata.
    """
    
    id: str
    title: str
    description: str
    content: str
    
    # Abstraction metadata
    abstraction_level: AbstractionLevel
    source_cluster_id: str
    subsumes: List[str]                     # IDs of specific strategies this replaces
    
    # Confidence in abstraction
    abstraction_confidence: float           # LLM's confidence in generalization
    validation_count: int = 0               # Times this abstract strategy succeeded
    
    # Embedding for retrieval
    embedding: List[float] = field(default_factory=list)
    
    # Lifecycle
    created_at: datetime = field(default_factory=datetime.now)
    last_validated: Optional[datetime] = None


@dataclass
class ConsolidationConfig:
    """Configuration for the strategy compressor."""
    
    # Clustering parameters
    algorithm: str = "hdbscan"              # "dbscan", "hdbscan", "agglomerative"
    min_cluster_size: int = 3               # Minimum strategies to form cluster
    distance_threshold: float = 0.3         # Max distance for same cluster
    
    # Abstraction parameters
    min_cohesion_for_abstraction: float = 0.7  # Only abstract tight clusters
    abstraction_model: str = "claude-3-sonnet" # LLM for abstraction
    
    # Scheduling
    consolidation_frequency_hours: int = 24
    min_new_strategies_to_trigger: int = 10
    
    # Retention
    keep_original_strategies: bool = True   # Keep specifics after abstraction
    original_retrieval_weight: float = 0.3  # Weight for original vs abstract


@dataclass 
class ConsolidationJob:
    """
    A scheduled consolidation run.
    """
    
    id: str
    started_at: datetime
    completed_at: Optional[datetime] = None
    
    # Input
    strategies_processed: int = 0
    
    # Output
    clusters_found: int = 0
    abstractions_created: int = 0
    
    # Cluster details
    cluster_ids: List[str] = field(default_factory=list)
    abstract_strategy_ids: List[str] = field(default_factory=list)
    
    # Quality metrics
    avg_cluster_cohesion: float = 0.0
    avg_abstraction_confidence: float = 0.0
    
    status: str = "running"  # "running", "completed", "failed"
    error: Optional[str] = None
```

### Consolidation Algorithm

```python
from typing import List, Tuple
import numpy as np


def run_consolidation(
    strategies: List['MemoryItem'],
    config: ConsolidationConfig
) -> ConsolidationJob:
    """
    Main consolidation pipeline.
    """
    job = ConsolidationJob(
        id=generate_id(),
        started_at=datetime.now(),
        strategies_processed=len(strategies)
    )
    
    try:
        # 1. Embed all strategies
        embeddings = np.array([s.embedding for s in strategies])
        
        # 2. Cluster
        clusters = cluster_strategies(embeddings, config)
        job.clusters_found = len(clusters)
        
        # 3. Abstract each cluster
        for cluster_indices in clusters:
            cluster_strategies = [strategies[i] for i in cluster_indices]
            
            # Check cohesion
            cohesion = calculate_cohesion(embeddings[cluster_indices])
            if cohesion < config.min_cohesion_for_abstraction:
                continue
            
            # Generate abstraction
            abstract = generate_abstraction(cluster_strategies, config)
            if abstract and abstract.abstraction_confidence > 0.6:
                save_abstract_strategy(abstract)
                job.abstract_strategy_ids.append(abstract.id)
                job.abstractions_created += 1
        
        job.status = "completed"
        job.completed_at = datetime.now()
        
    except Exception as e:
        job.status = "failed"
        job.error = str(e)
    
    return job


def cluster_strategies(
    embeddings: np.ndarray,
    config: ConsolidationConfig
) -> List[List[int]]:
    """
    Cluster strategy embeddings using configured algorithm.
    Returns list of clusters, each containing indices into embeddings.
    """
    if config.algorithm == "hdbscan":
        import hdbscan
        clusterer = hdbscan.HDBSCAN(
            min_cluster_size=config.min_cluster_size,
            metric='cosine'
        )
    elif config.algorithm == "dbscan":
        from sklearn.cluster import DBSCAN
        clusterer = DBSCAN(
            eps=config.distance_threshold,
            min_samples=config.min_cluster_size,
            metric='cosine'
        )
    else:
        raise ValueError(f"Unknown clustering algorithm: {config.algorithm}")
    
    labels = clusterer.fit_predict(embeddings)
    
    # Group indices by label (ignore noise label -1)
    clusters = {}
    for idx, label in enumerate(labels):
        if label >= 0:
            clusters.setdefault(label, []).append(idx)
    
    return list(clusters.values())


def calculate_cohesion(embeddings: np.ndarray) -> float:
    """
    Calculate cluster cohesion as average pairwise cosine similarity.
    """
    if len(embeddings) < 2:
        return 1.0
    
    from sklearn.metrics.pairwise import cosine_similarity
    sim_matrix = cosine_similarity(embeddings)
    
    # Average of upper triangle (excluding diagonal)
    n = len(embeddings)
    total = 0
    count = 0
    for i in range(n):
        for j in range(i + 1, n):
            total += sim_matrix[i, j]
            count += 1
    
    return total / count if count > 0 else 0.0


ABSTRACTION_PROMPT = """You are analyzing a cluster of related strategies that an AI agent has learned.

These strategies all address similar problems but were learned from different specific situations.

STRATEGIES IN CLUSTER:
{strategies}

TASK:
1. Identify the common principle or pattern across all these strategies
2. Create a single ABSTRACT strategy that captures this principle
3. The abstract strategy should be applicable to NEW situations similar to these

OUTPUT FORMAT:
Title: [Concise name for the abstract strategy]
Description: [One sentence explaining when to apply this]
Content: [Step-by-step guidance that generalizes across all input strategies]
Confidence: [0-1 score for how confident you are this abstraction is valid]

Focus on TRANSFERABLE principles, not specific details like exact commands or URLs."""


def generate_abstraction(
    strategies: List['MemoryItem'],
    config: ConsolidationConfig
) -> Optional[AbstractStrategy]:
    """
    Use LLM to abstract over a cluster of strategies.
    """
    # Format strategies for prompt
    strategy_text = "\n\n".join([
        f"Strategy {i+1}:\nTitle: {s.title}\nDescription: {s.description}\nContent: {s.content}"
        for i, s in enumerate(strategies)
    ])
    
    prompt = ABSTRACTION_PROMPT.format(strategies=strategy_text)
    
    # Call LLM (implementation depends on your setup)
    response = call_llm(prompt, model=config.abstraction_model)
    
    # Parse response
    parsed = parse_abstraction_response(response)
    if not parsed:
        return None
    
    return AbstractStrategy(
        id=generate_id(),
        title=parsed["title"],
        description=parsed["description"],
        content=parsed["content"],
        abstraction_level=AbstractionLevel.DOMAIN_GENERAL,
        source_cluster_id="pending",  # Set by caller
        subsumes=[s.id for s in strategies],
        abstraction_confidence=parsed["confidence"],
        embedding=embed_text(f"{parsed['title']} {parsed['description']} {parsed['content']}")
    )
```

### Integration with Procedural Memory

```python
class ProceduralMemoryWithConsolidation:
    """
    Extended procedural memory with strategy compression.
    """
    
    def __init__(self, config: ConsolidationConfig):
        self.config = config
        self.raw_strategies: List[MemoryItem] = []
        self.abstract_strategies: List[AbstractStrategy] = []
        self.clusters: List[StrategyCluster] = []
        self.last_consolidation: Optional[datetime] = None
    
    def recall(
        self, 
        query: str, 
        context: Optional[Dict] = None,
        prefer_abstract: bool = True
    ) -> List['MemoryItem']:
        """
        Retrieve strategies, optionally preferring abstract ones.
        """
        query_embedding = embed_text(query)
        
        candidates = []
        
        # Search abstract strategies
        if prefer_abstract and self.abstract_strategies:
            abstract_results = vector_search(
                query_embedding, 
                [s.embedding for s in self.abstract_strategies],
                k=3
            )
            for idx, score in abstract_results:
                candidates.append((
                    self.abstract_strategies[idx], 
                    score * 1.2  # Boost abstract strategies
                ))
        
        # Search raw strategies
        raw_results = vector_search(
            query_embedding,
            [s.embedding for s in self.raw_strategies],
            k=5
        )
        for idx, score in raw_results:
            # Reduce weight if subsumed by an abstract strategy
            strategy = self.raw_strategies[idx]
            if self._is_subsumed(strategy.id):
                score *= self.config.original_retrieval_weight
            candidates.append((strategy, score))
        
        # Sort by score and return top results
        candidates.sort(key=lambda x: x[1], reverse=True)
        return [c[0] for c in candidates[:5]]
    
    def _is_subsumed(self, strategy_id: str) -> bool:
        """Check if a strategy has been subsumed by an abstraction."""
        return any(
            strategy_id in abstract.subsumes 
            for abstract in self.abstract_strategies
        )
    
    def maybe_consolidate(self) -> Optional[ConsolidationJob]:
        """
        Run consolidation if conditions are met.
        """
        # Check if enough time has passed
        if self.last_consolidation:
            hours_since = (datetime.now() - self.last_consolidation).total_seconds() / 3600
            if hours_since < self.config.consolidation_frequency_hours:
                return None
        
        # Check if enough new strategies
        unconsolidated = [
            s for s in self.raw_strategies 
            if not self._is_subsumed(s.id)
        ]
        if len(unconsolidated) < self.config.min_new_strategies_to_trigger:
            return None
        
        # Run consolidation
        job = run_consolidation(unconsolidated, self.config)
        self.last_consolidation = datetime.now()
        
        return job
```

---

## Enhancement C: Metamemory FoK Regressor

### Problem Statement

The full SIMULATE operation requires LLM inference (~200ms+). For many queries, we can predict whether memory contains relevant information without full simulation.

### Proposed Solution

Train a lightweight "Feeling of Knowing" (FoK) classifier that predicts retrieval success.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      FAST-PATH ROUTER                                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│   USER QUERY                                                            │
│       │                                                                 │
│       ▼                                                                 │
│   ┌───────────────┐                                                     │
│   │  VECTORIZER   │  (Latency: <5ms)                                   │
│   │  (Cached)     │                                                     │
│   └───────┬───────┘                                                     │
│           │                                                             │
│           ▼                                                             │
│   ┌───────────────────────────────────────────────────────────────┐    │
│   │                    FoK REGRESSOR                               │    │
│   │                                                                │    │
│   │  Model: DistilBERT-tiny or Random Forest                      │    │
│   │  Input: Query embedding + memory statistics                    │    │
│   │  Output: P(memory contains relevant info)                      │    │
│   │                                                                │    │
│   │  Latency: <10ms                                                │    │
│   │                                                                │    │
│   └───────────────────────┬───────────────────────────────────────┘    │
│                           │                                             │
│               ┌───────────┴───────────┐                                │
│               │                       │                                 │
│         Score < 0.4             Score > 0.4                            │
│               │                       │                                 │
│               ▼                       ▼                                 │
│   ┌───────────────────┐   ┌───────────────────┐                        │
│   │    COLD PATH      │   │     HOT PATH      │                        │
│   │                   │   │                   │                        │
│   │  - Skip memory    │   │  - Query memory   │                        │
│   │  - Use web search │   │  - Full retrieval │                        │
│   │  - Use base LLM   │   │  - SIMULATE if    │                        │
│   │                   │   │    needed         │                        │
│   └───────────────────┘   └───────────────────┘                        │
│                                                                         │
│   FEEDBACK LOOP                                                         │
│   ─────────────                                                         │
│   │ After response, record:                                            │
│   │ - FoK prediction                                                   │
│   │ - Actual retrieval success                                         │
│   │ - User satisfaction signal                                         │
│   │                                                                     │
│   │ Retrain regressor weekly on accumulated data                       │
│   └─────────────────────────────────────────────────────────────────── │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Schema Extension

```python
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Optional, Dict
from enum import Enum


class RetrievalPath(Enum):
    """Which retrieval path was taken."""
    HOT = "hot"         # Memory retrieval
    COLD = "cold"       # External search / base model
    HYBRID = "hybrid"   # Both


@dataclass
class FoKPrediction:
    """
    A Feeling of Knowing prediction and its outcome.
    Used for training the FoK regressor.
    """
    
    id: str
    
    # Input
    query: str
    query_embedding: List[float]
    
    # Memory statistics at prediction time
    memory_stats: Dict[str, float] = field(default_factory=dict)
    # {
    #   "declarative_size": 1234,
    #   "procedural_size": 567,
    #   "recent_hits_rate": 0.7,
    #   "domain_coverage": 0.5,
    #   ...
    # }
    
    # Prediction
    fok_score: float                    # Model's predicted P(has_info)
    predicted_path: RetrievalPath
    
    # Actual outcome
    actual_retrieval_success: Optional[bool] = None
    retrieval_relevance_score: Optional[float] = None  # 0-1 relevance of retrieved items
    user_satisfaction: Optional[float] = None          # Thumbs up/down signal
    
    # Timing
    predicted_at: datetime = field(default_factory=datetime.now)
    resolved_at: Optional[datetime] = None
    
    @property
    def prediction_error(self) -> Optional[float]:
        """Absolute error between prediction and outcome."""
        if self.actual_retrieval_success is None:
            return None
        actual = 1.0 if self.actual_retrieval_success else 0.0
        return abs(self.fok_score - actual)


@dataclass
class FoKRegressorConfig:
    """Configuration for the FoK regressor."""
    
    # Model selection
    model_type: str = "random_forest"   # "random_forest", "distilbert", "logistic"
    
    # Features
    use_query_embedding: bool = True
    use_memory_stats: bool = True
    use_temporal_features: bool = True  # Time of day, recency
    
    # Thresholds
    hot_path_threshold: float = 0.4     # Score above this -> query memory
    cold_path_threshold: float = 0.2    # Score below this -> skip memory
    
    # Training
    min_samples_to_train: int = 100
    retrain_frequency_days: int = 7
    validation_split: float = 0.2
    
    # Serving
    max_latency_ms: float = 10.0


@dataclass
class FoKRegressor:
    """
    The Feeling of Knowing regressor model.
    """
    
    config: FoKRegressorConfig
    
    # Model state (serialized separately)
    model_version: str = "untrained"
    trained_at: Optional[datetime] = None
    training_samples: int = 0
    
    # Performance metrics
    validation_accuracy: float = 0.0
    validation_auc: float = 0.0
    mean_latency_ms: float = 0.0
    
    # Training data buffer
    training_buffer: List[FoKPrediction] = field(default_factory=list)
    
    def predict(self, query_embedding: List[float], memory_stats: Dict) -> float:
        """
        Predict P(memory contains relevant info).
        Must complete in <10ms.
        """
        # Implementation depends on model_type
        raise NotImplementedError("Implement based on chosen model")
    
    def route(self, fok_score: float) -> RetrievalPath:
        """Decide retrieval path based on FoK score."""
        if fok_score > self.config.hot_path_threshold:
            return RetrievalPath.HOT
        elif fok_score < self.config.cold_path_threshold:
            return RetrievalPath.COLD
        else:
            return RetrievalPath.HYBRID
    
    def record_outcome(self, prediction_id: str, success: bool, relevance: float):
        """Record actual outcome for training."""
        for pred in self.training_buffer:
            if pred.id == prediction_id:
                pred.actual_retrieval_success = success
                pred.retrieval_relevance_score = relevance
                pred.resolved_at = datetime.now()
                break
    
    def should_retrain(self) -> bool:
        """Check if retraining is needed."""
        resolved = [p for p in self.training_buffer if p.actual_retrieval_success is not None]
        
        if len(resolved) < self.config.min_samples_to_train:
            return False
        
        if self.trained_at is None:
            return True
        
        days_since = (datetime.now() - self.trained_at).days
        return days_since >= self.config.retrain_frequency_days
```

### Implementation Sketch

```python
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score


class FoKRegressorImpl:
    """
    Random Forest implementation of FoK regressor.
    Chosen for: fast inference, interpretability, no GPU required.
    """
    
    def __init__(self, config: FoKRegressorConfig):
        self.config = config
        self.model = None
        self.feature_names = []
    
    def _extract_features(
        self, 
        query_embedding: List[float], 
        memory_stats: Dict
    ) -> np.ndarray:
        """Extract feature vector for prediction."""
        features = []
        
        # Query embedding (dimensionality reduced if needed)
        if self.config.use_query_embedding:
            # Use first 64 dimensions or PCA-reduced
            emb = np.array(query_embedding[:64])
            features.extend(emb.tolist())
        
        # Memory statistics
        if self.config.use_memory_stats:
            stat_features = [
                memory_stats.get("declarative_size", 0) / 10000,  # Normalized
                memory_stats.get("procedural_size", 0) / 1000,
                memory_stats.get("recent_hits_rate", 0.5),
                memory_stats.get("domain_coverage", 0.5),
                memory_stats.get("avg_fact_confidence", 0.5),
                memory_stats.get("days_since_last_update", 30) / 30,
            ]
            features.extend(stat_features)
        
        # Temporal features
        if self.config.use_temporal_features:
            now = datetime.now()
            temporal = [
                now.hour / 24,  # Time of day
                now.weekday() / 7,  # Day of week
            ]
            features.extend(temporal)
        
        return np.array(features)
    
    def train(self, training_data: List[FoKPrediction]):
        """Train the regressor on accumulated data."""
        # Filter to resolved predictions
        resolved = [p for p in training_data if p.actual_retrieval_success is not None]
        
        if len(resolved) < self.config.min_samples_to_train:
            raise ValueError(f"Need at least {self.config.min_samples_to_train} samples")
        
        # Extract features and labels
        X = np.array([
            self._extract_features(p.query_embedding, p.memory_stats)
            for p in resolved
        ])
        y = np.array([1 if p.actual_retrieval_success else 0 for p in resolved])
        
        # Split
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, 
            test_size=self.config.validation_split,
            random_state=42
        )
        
        # Train
        self.model = RandomForestClassifier(
            n_estimators=50,        # Keep small for speed
            max_depth=10,
            n_jobs=-1,
            random_state=42
        )
        self.model.fit(X_train, y_train)
        
        # Evaluate
        y_pred = self.model.predict(X_val)
        y_prob = self.model.predict_proba(X_val)[:, 1]
        
        accuracy = accuracy_score(y_val, y_pred)
        auc = roc_auc_score(y_val, y_prob)
        
        return {
            "accuracy": accuracy,
            "auc": auc,
            "train_size": len(X_train),
            "val_size": len(X_val)
        }
    
    def predict(self, query_embedding: List[float], memory_stats: Dict) -> float:
        """
        Predict P(memory contains relevant info).
        Returns 0.5 if model not trained.
        """
        if self.model is None:
            return 0.5  # Default to hybrid path
        
        features = self._extract_features(query_embedding, memory_stats)
        prob = self.model.predict_proba([features])[0, 1]
        return float(prob)


class FastPathRouter:
    """
    Routes queries to hot/cold path based on FoK prediction.
    """
    
    def __init__(self, fok_regressor: FoKRegressorImpl, memory: 'UnifiedMemory'):
        self.fok = fok_regressor
        self.memory = memory
    
    def route_query(self, query: str) -> tuple:
        """
        Route query and return (path, fok_score, prediction_id).
        """
        # Embed query
        query_embedding = embed_text(query)
        
        # Get memory statistics
        memory_stats = self._get_memory_stats()
        
        # Predict
        fok_score = self.fok.predict(query_embedding, memory_stats)
        
        # Record prediction
        prediction = FoKPrediction(
            id=generate_id(),
            query=query,
            query_embedding=query_embedding,
            memory_stats=memory_stats,
            fok_score=fok_score,
            predicted_path=self._score_to_path(fok_score)
        )
        self.fok.training_buffer.append(prediction)
        
        return (prediction.predicted_path, fok_score, prediction.id)
    
    def _get_memory_stats(self) -> Dict:
        """Gather current memory statistics."""
        return {
            "declarative_size": len(self.memory.declarative.get_all()),
            "procedural_size": len(self.memory.procedural.get_all()),
            "recent_hits_rate": self._calculate_recent_hits_rate(),
            "domain_coverage": self._estimate_domain_coverage(),
            "avg_fact_confidence": self._avg_fact_confidence(),
            "days_since_last_update": self._days_since_update(),
        }
    
    def _score_to_path(self, score: float) -> RetrievalPath:
        """Convert FoK score to retrieval path."""
        if score > self.fok.config.hot_path_threshold:
            return RetrievalPath.HOT
        elif score < self.fok.config.cold_path_threshold:
            return RetrievalPath.COLD
        else:
            return RetrievalPath.HYBRID
```

---

## Implementation Roadmap

### Phase 2a: Strategy Compressor (2-3 weeks)

1. **Week 1:** Implement clustering infrastructure
   - Add HDBSCAN dependency
   - Create StrategyCluster and ConsolidationJob schemas
   - Build clustering pipeline

2. **Week 2:** Implement LLM abstraction
   - Design and test abstraction prompt
   - Build AbstractStrategy generation
   - Integrate with ProceduralMemory

3. **Week 3:** Testing and tuning
   - Tune clustering parameters
   - Evaluate abstraction quality
   - Benchmark retrieval with abstractions

### Phase 2b: FoK Regressor (2-3 weeks)

1. **Week 1:** Data collection
   - Add FoKPrediction logging
   - Instrument retrieval outcomes
   - Accumulate training data

2. **Week 2:** Model training
   - Implement RandomForest FoK
   - Train on accumulated data
   - Evaluate accuracy/AUC

3. **Week 3:** Router integration
   - Build FastPathRouter
   - A/B test hot/cold routing
   - Measure latency improvement

---

## Success Metrics

### Strategy Compressor

| Metric | Target | Measurement |
|--------|--------|-------------|
| Cluster purity | >0.8 | Strategies in cluster share domain |
| Abstraction validity | >70% | Abstract strategies succeed when applied |
| Retrieval relevance | +10% | MRR improvement with abstractions |
| Storage efficiency | -30% | Reduction in effective strategy count |

### FoK Regressor

| Metric | Target | Measurement |
|--------|--------|-------------|
| Prediction accuracy | >75% | Correct hot/cold routing |
| AUC-ROC | >0.8 | Ranking quality |
| Latency reduction | >50% | Cold path skips memory entirely |
| P95 latency | <250ms | End-to-end with routing |

---

## Dependencies

**Strategy Compressor:**
- `hdbscan` or `scikit-learn` for clustering
- LLM API for abstraction generation
- Scheduled job infrastructure

**FoK Regressor:**
- `scikit-learn` for Random Forest
- Outcome logging infrastructure
- A/B testing framework

---

*Enhancement Specification v1.1 - December 2024*
*Source: Technical Review Recommendations*
